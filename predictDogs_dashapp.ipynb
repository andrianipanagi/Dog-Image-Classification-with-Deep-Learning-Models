{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the model from the saved HDF5 file\n",
        "model = load_model('/content/model.h5')"
      ],
      "metadata": {
        "id": "F0qc9M-1wCfG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_to_class = {0: 'afghan_hound',\n",
        " 1: 'african_hunting_dog',\n",
        " 2: 'airedale',\n",
        " 3: 'american_staffordshire_terrier',\n",
        " 4: 'appenzeller',\n",
        " 5: 'australian_terrier',\n",
        " 6: 'bedlington_terrier',\n",
        " 7: 'bernese_mountain_dog',\n",
        " 8: 'blenheim_spaniel',\n",
        " 9: 'border_collie',\n",
        " 10: 'border_terrier',\n",
        " 11: 'boston_bull',\n",
        " 12: 'bouvier_des_flandres',\n",
        " 13: 'brabancon_griffon',\n",
        " 14: 'brittany_spaniel',\n",
        " 15: 'cardigan',\n",
        " 16: 'chesapeake_bay_retriever',\n",
        " 17: 'chihuahua',\n",
        " 18: 'dandie_dinmont',\n",
        " 19: 'doberman',\n",
        " 20: 'english_foxhound',\n",
        " 21: 'english_setter',\n",
        " 22: 'english_springer',\n",
        " 23: 'entlebucher',\n",
        " 24: 'eskimo_dog',\n",
        " 25: 'french_bulldog',\n",
        " 26: 'german_shepherd',\n",
        " 27: 'german_short-haired_pointer',\n",
        " 28: 'gordon_setter',\n",
        " 29: 'great_dane',\n",
        " 30: 'great_pyrenees',\n",
        " 31: 'greater_swiss_mountain_dog',\n",
        " 32: 'ibizan_hound',\n",
        " 33: 'irish_setter',\n",
        " 34: 'irish_terrier',\n",
        " 35: 'irish_water_spaniel',\n",
        " 36: 'irish_wolfhound',\n",
        " 37: 'italian_greyhound',\n",
        " 38: 'japanese_spaniel',\n",
        " 39: 'kerry_blue_terrier',\n",
        " 40: 'labrador_retriever',\n",
        " 41: 'lakeland_terrier',\n",
        " 42: 'leonberg',\n",
        " 43: 'lhasa',\n",
        " 44: 'maltese_dog',\n",
        " 45: 'mexican_hairless',\n",
        " 46: 'newfoundland',\n",
        " 47: 'norfolk_terrier',\n",
        " 48: 'norwegian_elkhound',\n",
        " 49: 'norwich_terrier',\n",
        " 50: 'old_english_sheepdog',\n",
        " 51: 'pekinese',\n",
        " 52: 'pembroke',\n",
        " 53: 'pomeranian',\n",
        " 54: 'rhodesian_ridgeback',\n",
        " 55: 'rottweiler',\n",
        " 56: 'saint_bernard',\n",
        " 57: 'saluki',\n",
        " 58: 'samoyed',\n",
        " 59: 'scotch_terrier',\n",
        " 60: 'scottish_deerhound',\n",
        " 61: 'sealyham_terrier',\n",
        " 62: 'shetland_sheepdog',\n",
        " 63: 'shih-tzu',\n",
        " 64: 'siberian_husky',\n",
        " 65: 'staffordshire_bullterrier',\n",
        " 66: 'sussex_spaniel',\n",
        " 67: 'tibetan_mastiff',\n",
        " 68: 'tibetan_terrier',\n",
        " 69: 'walker_hound',\n",
        " 70: 'weimaraner',\n",
        " 71: 'welsh_springer_spaniel',\n",
        " 72: 'west_highland_white_terrier',\n",
        " 73: 'yorkshire_terrier',\n",
        " 74: 'affenpinscher',\n",
        " 75: 'basenji',\n",
        " 76: 'basset',\n",
        " 77: 'beagle',\n",
        " 78: 'black-and-tan_coonhound',\n",
        " 79: 'bloodhound',\n",
        " 80: 'bluetick',\n",
        " 81: 'borzoi',\n",
        " 82: 'boxer',\n",
        " 83: 'briard',\n",
        " 84: 'bull_mastiff',\n",
        " 85: 'cairn',\n",
        " 86: 'chow',\n",
        " 87: 'clumber',\n",
        " 88: 'cocker_spaniel',\n",
        " 89: 'collie',\n",
        " 90: 'curly-coated_retriever',\n",
        " 91: 'dhole',\n",
        " 92: 'dingo',\n",
        " 93: 'flat-coated_retriever',\n",
        " 94: 'giant_schnauzer',\n",
        " 95: 'golden_retriever',\n",
        " 96: 'groenendael',\n",
        " 97: 'keeshond',\n",
        " 98: 'kelpie',\n",
        " 99: 'komondor',\n",
        " 100: 'kuvasz',\n",
        " 101: 'malamute',\n",
        " 102: 'malinois',\n",
        " 103: 'miniature_pinscher',\n",
        " 104: 'miniature_poodle',\n",
        " 105: 'miniature_schnauzer',\n",
        " 106: 'otterhound',\n",
        " 107: 'papillon',\n",
        " 108: 'pug',\n",
        " 109: 'redbone',\n",
        " 110: 'schipperke',\n",
        " 111: 'silky_terrier',\n",
        " 112: 'soft-coated_wheaten_terrier',\n",
        " 113: 'standard_poodle',\n",
        " 114: 'standard_schnauzer',\n",
        " 115: 'toy_poodle',\n",
        " 116: 'toy_terrier',\n",
        " 117: 'vizsla',\n",
        " 118: 'whippet',\n",
        " 119: 'wire-haired_fox_terrier'}"
      ],
      "metadata": {
        "id": "3eEwERq3uK_m"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HklcT-qMsJmr"
      },
      "outputs": [],
      "source": [
        "# # Define the function to preprocess a single image\n",
        "# def preprocess_image(image_path):\n",
        "#     image = tf.io.read_file(image_path)\n",
        "#     image = tf.image.decode_jpeg(image, channels=3)\n",
        "#     image = tf.image.resize(image, [224, 224])  # Adjust as needed\n",
        "#     image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
        "#     return image\n",
        "\n",
        "# # Function to predict label for a single image\n",
        "# def predict_label(image_path):\n",
        "#     # Preprocess the image\n",
        "#     image = preprocess_image(image_path)\n",
        "#     # Add an extra dimension as models usually expect a batch of images\n",
        "#     image = tf.expand_dims(image, axis=0)\n",
        "#     # Get the predicted probabilities from the model\n",
        "#     predicted_probs = model.predict(image)\n",
        "#     # Get the index of the predicted label\n",
        "#     predicted_label_index = np.argmax(predicted_probs)\n",
        "#     return predicted_label_index\n",
        "\n",
        "def load_and_preprocess_image(image_path):\n",
        "    # Read image file\n",
        "    img = tf.io.read_file(image_path)\n",
        "    # Decode image to a tensor\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    # Resize the image to the required dimensions\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    # Normalize the pixel values to [0, 1]\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img\n",
        "\n",
        "def predict_image(image_path):\n",
        "    # Load and preprocess the image\n",
        "    processed_image = load_and_preprocess_image(image_path)\n",
        "\n",
        "    # Reshape the image to a batch of 1 (since you're predicting a single image)\n",
        "    processed_image = tf.expand_dims(processed_image, axis=0)\n",
        "\n",
        "    # Change the directory to where your model is saved\n",
        "    os.chdir('/content')\n",
        "\n",
        "    # Make predictions on the processed image\n",
        "    predictions = model.predict(processed_image)\n",
        "\n",
        "    # Decode the predictions to obtain the predicted class index\n",
        "    predicted_class_index = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    # Map the predicted class index to the class name using label_to_class dictionary\n",
        "    predicted_class = label_to_class[predicted_class_index]\n",
        "\n",
        "    # Show the image\n",
        "    plt.imshow(processed_image[0])\n",
        "    plt.title(f\"Predicted class: {predicted_class}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage: Provide the path to an image you want to predict\n",
        "image_path_to_predict = '/content/beagle.jpg'\n",
        "# image_path_to_predict = '/content/chihuahua.jpg'\n",
        "# image_path_to_predict = '/content/golden_retriever.jpeg'\n",
        "predict_image(image_path_to_predict)"
      ],
      "metadata": {
        "id": "h82wtBLBtiwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dash==2.13.0 # Required to run in Google Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbwJvCvw5U_j",
        "outputId": "49b961a9-46dc-476c-875b-9a1bc49b10e9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dash==2.13.0\n",
            "  Downloading dash-2.13.0-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask<2.3.0,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash==2.13.0) (2.2.5)\n",
            "Collecting Werkzeug<2.3.0 (from dash==2.13.0)\n",
            "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash==2.13.0) (5.15.0)\n",
            "Collecting dash-html-components==2.0.0 (from dash==2.13.0)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Collecting dash-core-components==2.0.0 (from dash==2.13.0)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting dash-table==5.0.0 (from dash==2.13.0)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash==2.13.0) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash==2.13.0) (2.31.0)\n",
            "Collecting retrying (from dash==2.13.0)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Collecting ansi2html (from dash==2.13.0)\n",
            "  Downloading ansi2html-1.8.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash==2.13.0) (1.5.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash==2.13.0) (67.7.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<2.3.0,>=1.0.4->dash==2.13.0) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<2.3.0,>=1.0.4->dash==2.13.0) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<2.3.0,>=1.0.4->dash==2.13.0) (8.1.7)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash==2.13.0) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash==2.13.0) (23.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug<2.3.0->dash==2.13.0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash==2.13.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash==2.13.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash==2.13.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash==2.13.0) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->dash==2.13.0) (1.16.0)\n",
            "Installing collected packages: dash-table, dash-html-components, dash-core-components, Werkzeug, retrying, ansi2html, dash\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 3.0.1\n",
            "    Uninstalling Werkzeug-3.0.1:\n",
            "      Successfully uninstalled Werkzeug-3.0.1\n",
            "Successfully installed Werkzeug-2.2.3 ansi2html-1.8.0 dash-2.13.0 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 retrying-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dash\n",
        "from dash import html, dcc\n",
        "from dash.dependencies import Input, Output\n",
        "import base64\n",
        "import tensorflow as tf\n",
        "import io\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "# Assuming you have label_to_class as a dictionary mapping label indices to class names\n",
        "label_to_class = {0: 'afghan_hound',\n",
        " 1: 'african_hunting_dog',\n",
        " 2: 'airedale',\n",
        " 3: 'american_staffordshire_terrier',\n",
        " 4: 'appenzeller',\n",
        " 5: 'australian_terrier',\n",
        " 6: 'bedlington_terrier',\n",
        " 7: 'bernese_mountain_dog',\n",
        " 8: 'blenheim_spaniel',\n",
        " 9: 'border_collie',\n",
        " 10: 'border_terrier',\n",
        " 11: 'boston_bull',\n",
        " 12: 'bouvier_des_flandres',\n",
        " 13: 'brabancon_griffon',\n",
        " 14: 'brittany_spaniel',\n",
        " 15: 'cardigan',\n",
        " 16: 'chesapeake_bay_retriever',\n",
        " 17: 'chihuahua',\n",
        " 18: 'dandie_dinmont',\n",
        " 19: 'doberman',\n",
        " 20: 'english_foxhound',\n",
        " 21: 'english_setter',\n",
        " 22: 'english_springer',\n",
        " 23: 'entlebucher',\n",
        " 24: 'eskimo_dog',\n",
        " 25: 'french_bulldog',\n",
        " 26: 'german_shepherd',\n",
        " 27: 'german_short-haired_pointer',\n",
        " 28: 'gordon_setter',\n",
        " 29: 'great_dane',\n",
        " 30: 'great_pyrenees',\n",
        " 31: 'greater_swiss_mountain_dog',\n",
        " 32: 'ibizan_hound',\n",
        " 33: 'irish_setter',\n",
        " 34: 'irish_terrier',\n",
        " 35: 'irish_water_spaniel',\n",
        " 36: 'irish_wolfhound',\n",
        " 37: 'italian_greyhound',\n",
        " 38: 'japanese_spaniel',\n",
        " 39: 'kerry_blue_terrier',\n",
        " 40: 'labrador_retriever',\n",
        " 41: 'lakeland_terrier',\n",
        " 42: 'leonberg',\n",
        " 43: 'lhasa',\n",
        " 44: 'maltese_dog',\n",
        " 45: 'mexican_hairless',\n",
        " 46: 'newfoundland',\n",
        " 47: 'norfolk_terrier',\n",
        " 48: 'norwegian_elkhound',\n",
        " 49: 'norwich_terrier',\n",
        " 50: 'old_english_sheepdog',\n",
        " 51: 'pekinese',\n",
        " 52: 'pembroke',\n",
        " 53: 'pomeranian',\n",
        " 54: 'rhodesian_ridgeback',\n",
        " 55: 'rottweiler',\n",
        " 56: 'saint_bernard',\n",
        " 57: 'saluki',\n",
        " 58: 'samoyed',\n",
        " 59: 'scotch_terrier',\n",
        " 60: 'scottish_deerhound',\n",
        " 61: 'sealyham_terrier',\n",
        " 62: 'shetland_sheepdog',\n",
        " 63: 'shih-tzu',\n",
        " 64: 'siberian_husky',\n",
        " 65: 'staffordshire_bullterrier',\n",
        " 66: 'sussex_spaniel',\n",
        " 67: 'tibetan_mastiff',\n",
        " 68: 'tibetan_terrier',\n",
        " 69: 'walker_hound',\n",
        " 70: 'weimaraner',\n",
        " 71: 'welsh_springer_spaniel',\n",
        " 72: 'west_highland_white_terrier',\n",
        " 73: 'yorkshire_terrier',\n",
        " 74: 'affenpinscher',\n",
        " 75: 'basenji',\n",
        " 76: 'basset',\n",
        " 77: 'beagle',\n",
        " 78: 'black-and-tan_coonhound',\n",
        " 79: 'bloodhound',\n",
        " 80: 'bluetick',\n",
        " 81: 'borzoi',\n",
        " 82: 'boxer',\n",
        " 83: 'briard',\n",
        " 84: 'bull_mastiff',\n",
        " 85: 'cairn',\n",
        " 86: 'chow',\n",
        " 87: 'clumber',\n",
        " 88: 'cocker_spaniel',\n",
        " 89: 'collie',\n",
        " 90: 'curly-coated_retriever',\n",
        " 91: 'dhole',\n",
        " 92: 'dingo',\n",
        " 93: 'flat-coated_retriever',\n",
        " 94: 'giant_schnauzer',\n",
        " 95: 'golden_retriever',\n",
        " 96: 'groenendael',\n",
        " 97: 'keeshond',\n",
        " 98: 'kelpie',\n",
        " 99: 'komondor',\n",
        " 100: 'kuvasz',\n",
        " 101: 'malamute',\n",
        " 102: 'malinois',\n",
        " 103: 'miniature_pinscher',\n",
        " 104: 'miniature_poodle',\n",
        " 105: 'miniature_schnauzer',\n",
        " 106: 'otterhound',\n",
        " 107: 'papillon',\n",
        " 108: 'pug',\n",
        " 109: 'redbone',\n",
        " 110: 'schipperke',\n",
        " 111: 'silky_terrier',\n",
        " 112: 'soft-coated_wheaten_terrier',\n",
        " 113: 'standard_poodle',\n",
        " 114: 'standard_schnauzer',\n",
        " 115: 'toy_poodle',\n",
        " 116: 'toy_terrier',\n",
        " 117: 'vizsla',\n",
        " 118: 'whippet',\n",
        " 119: 'wire-haired_fox_terrier'}\n",
        "\n",
        "# Function to preprocess the uploaded image\n",
        "def preprocess_image(content):\n",
        "    # Decode the image content\n",
        "    content_type, content_string = content.split(',')\n",
        "    decoded = base64.b64decode(content_string)\n",
        "    image = tf.image.decode_jpeg(decoded, channels=3)\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image\n",
        "\n",
        "# Function to predict the top 5 labels and their probabilities for the uploaded image\n",
        "def predict_image(image):\n",
        "    # Reshape the image to a batch of 1 (since you're predicting a single image)\n",
        "    processed_image = tf.expand_dims(image, axis=0)\n",
        "\n",
        "    # Make predictions on the processed image\n",
        "    predictions = model.predict(processed_image)\n",
        "\n",
        "    # Get the top 5 prediction indices\n",
        "    top_5_indices = tf.argsort(predictions[0], direction='DESCENDING')[:5].numpy()\n",
        "\n",
        "    # Get the corresponding class names and probabilities for the top 5 predictions\n",
        "    top_5_labels = [label_to_class.get(index, \"Unknown\") for index in top_5_indices]\n",
        "    top_5_probabilities = [predictions[0][index] for index in top_5_indices]\n",
        "\n",
        "    return top_5_labels, top_5_probabilities\n",
        "\n",
        "app = dash.Dash(__name__)\n",
        "\n",
        "app.layout = html.Div([\n",
        "    html.H1(\"Image Classifier\"),\n",
        "    dcc.Upload(\n",
        "        id='upload-image',\n",
        "        children=html.Div([\n",
        "            'Drag and Drop or ',\n",
        "            html.A('Select Files')\n",
        "        ]),\n",
        "        style={\n",
        "            'width': '100%',\n",
        "            'height': '60px',\n",
        "            'lineHeight': '60px',\n",
        "            'borderWidth': '1px',\n",
        "            'borderStyle': 'dashed',\n",
        "            'borderRadius': '5px',\n",
        "            'textAlign': 'center',\n",
        "            'margin': '10px'\n",
        "        },\n",
        "        # Allow multiple files to be uploaded\n",
        "        multiple=False\n",
        "    ),\n",
        "    html.Div(id='output-prediction', style={'marginTop': '20px'}),\n",
        "    html.Div([\n",
        "        html.H4(\"Processed Image:\"),\n",
        "        html.Img(id='output-image', style={'width': '50%', 'display': 'block', 'margin': 'auto'})\n",
        "    ])\n",
        "])\n",
        "\n",
        "@app.callback(\n",
        "    Output('output-prediction', 'children'),\n",
        "    Output('output-image', 'src'),\n",
        "    Input('upload-image', 'contents')\n",
        ")\n",
        "def update_output(content):\n",
        "    if content is not None:\n",
        "        # Preprocess the uploaded image\n",
        "        processed_image = preprocess_image(content)\n",
        "\n",
        "        # Predict the top 5 labels and probabilities for the uploaded image\n",
        "        top_5_labels, top_5_probabilities = predict_image(processed_image)\n",
        "\n",
        "        # Encode the processed image to base64 for display\n",
        "        pil_img = tf.keras.preprocessing.image.array_to_img(processed_image)\n",
        "        buffered = io.BytesIO()\n",
        "        pil_img.save(buffered, format=\"PNG\")\n",
        "        encoded_image = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
        "\n",
        "        # Create a list of top 5 labels with their probabilities\n",
        "        label_prob_list = [f\"{label}: {prob:.2%}\" for label, prob in zip(top_5_labels, top_5_probabilities)]\n",
        "\n",
        "        return (\n",
        "            html.Div([\n",
        "                html.H4(\"Top 5 Predictions:\"),\n",
        "                html.Ul([html.Li(label_prob) for label_prob in label_prob_list])\n",
        "            ]),\n",
        "            f'data:image/png;base64,{encoded_image}'\n",
        "        )\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load your model here\n",
        "    # model = load_model('/content/model.h5')\n",
        "    app.run_server(mode=\"inline\", host=\"localhost\", port=8051)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "26BF03C74TDT",
        "outputId": "8e00e251-91de-44e8-82fa-23d6c4c299e7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8051, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}